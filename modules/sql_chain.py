# modules/sql_chain.py

from langchain.prompts import PromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from modules.utils import load_schema_string
import traceback

# 1. Prompt with schema and question
sql_prompt = PromptTemplate.from_template("""
ë‹¤ìŒì€ ëŒ€êµ¬ì‹œ ê±´ì¶•ë¬¼/ì—ë„ˆì§€/ì¸êµ¬ ë°ì´í„°ë² ì´ìŠ¤ì˜ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆì…ë‹ˆë‹¤.

{schema}

ì‚¬ìš©ìê°€ ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ì„ í–ˆìŠµë‹ˆë‹¤:

ì§ˆë¬¸: {question}

ìœ„ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ SQL ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
- ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
- ì¿¼ë¦¬ë§Œ ì¶œë ¥í•˜ê³  ì£¼ì„, ì„¤ëª…, ê¸°íƒ€ ë¬¸ì¥ì€ ë„£ì§€ ë§ˆì„¸ìš”.
- í…Œì´ë¸” ì´ë¦„ì€ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤: building_daegu, energy_daegu, population
- ì»¬ëŸ¼ ì´ë¦„ì´ ê´„í˜¸ë‚˜ íŠ¹ìˆ˜ë¬¸ìë¥¼ í¬í•¨í•˜ëŠ” ê²½ìš°, ë°˜ë“œì‹œ í°ë”°ì˜´í‘œ(")ë¡œ ê°ì‹¸ì„œ ì‚¬ìš©í•˜ì„¸ìš”.

SQL:
""")

# 2. LLM
llm = ChatOpenAI(model="gpt-4", temperature=0)

# 3. Chain
sql_chain = LLMChain(llm=llm, prompt=sql_prompt)

# 4. Main function
def generate_sql(question: str) -> str:
    try:
        # âœ… Load schema
        schema_str = load_schema_string("db_schema.json")

        # âœ… Optional: truncate if too long
        schema_lines = schema_str.split("\n")
        schema_str = "\n".join(schema_lines[:500])

        # âœ… Generate SQL
        print("ğŸ§  Generating SQL using LLM...")
        sql = sql_chain.run({"question": question, "schema": schema_str})
        print("âœ… Generated SQL:", sql)
        return sql.strip()

    except Exception as e:
        print("âŒ SQL generation error:", str(e))
        traceback.print_exc()
        return f"[ì˜¤ë¥˜ ë°œìƒ]: {str(e)}"
