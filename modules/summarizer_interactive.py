# summarizer_interactive.py

import pandas as pd
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI


# ğŸ“Œ Load OpenAI model
llm = ChatOpenAI(temperature=0, model="gpt-4o")

# ğŸ§  Template for summarizing SQL result
summary_prompt = PromptTemplate(
    input_variables=["question", "result"],
    template="""
ë‹¹ì‹ ì€ ëŒ€êµ¬ì‹œì˜ ê±´ì¶•ë¬¼, ì¸êµ¬, ì—ë„ˆì§€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•´ SQLë¡œ ì¡°íšŒëœ í‘œ í˜•ì‹ì˜ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ í‘œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì§€ì¹¨ì— ë”°ë¼ ì •í™•í•˜ê³  ê°„ê²°í•œ í•œêµ­ì–´ ìš”ì•½ì„ ìƒì„±í•˜ì„¸ìš”:

[ìš”ì•½ ì§€ì¹¨]
- í•µì‹¬ ìˆ˜ì¹˜(ì˜ˆ: í•©ê³„, í‰ê· , ìƒìœ„ê°’, ë¹„ìœ¨ ë“±)ë¥¼ ë¬¸ì¥ì— í¬í•¨í•˜ì„¸ìš”.
- ì§€ì—­ëª…, ì—°ë„, ìš©ë„, ì—ë„ˆì§€ ì¢…ë¥˜(ì „ê¸°/ë„ì‹œê°€ìŠ¤ ë“±)ë¥¼ ëª…í™•íˆ ì–¸ê¸‰í•˜ì„¸ìš”.
- ê²°ê³¼ê°€ ë¹„ì–´ ìˆë‹¤ë©´ "ì¡°íšŒëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ì‘ë‹µí•˜ì„¸ìš”.
- í‘œë¥¼ ê·¸ëŒ€ë¡œ ë‚˜ì—´í•˜ì§€ ë§ê³  ìš”ì ì„ ìš”ì•½í•œ ë¬¸ì¥ 2~4ê°œë¡œ êµ¬ì„±í•˜ì„¸ìš”.
- ê²°ê³¼ê°€ ë§ì€ ê²½ìš° ìƒìœ„ 3ê°œë§Œ ëŒ€í‘œë¡œ ì–¸ê¸‰í•˜ê³  ê·¸ ì™¸ëŠ” "ë“±"ìœ¼ë¡œ ì²˜ë¦¬í•˜ì„¸ìš”.
- ìˆ«ìì—ëŠ” ë‹¨ìœ„ë¥¼ ë¶™ì´ì„¸ìš” (ì˜ˆ: 15,000kWh, 120ê±´, 12.3%)

[ì‚¬ìš©ì ì§ˆë¬¸]
{question}

[SQL ê²°ê³¼]
{result}

[ì‘ë‹µ]
"""
)

# ğŸ§  Chain for LLM summarization
summary_chain = LLMChain(llm=llm, prompt=summary_prompt)


# ğŸ¯ Entry function
def summarize_result(question: str, df: pd.DataFrame) -> str:
    if df.empty:
        return "ì¡°íšŒëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    # Reduce large result for LLM context
    max_rows = 15
    display_df = df.head(max_rows).copy()

    # Simplify long column names
    display_df.columns = [col.strip()[:40] for col in display_df.columns]

    # Format result as text
    result_str = display_df.to_string(index=False)

    # Run through LLM
    summary = summary_chain.run({"question": question, "result": result_str})
    return summary.strip()
